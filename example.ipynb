{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283e6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from visualize_events.snomed import *\n",
    "from visualize_events.data import *\n",
    "from visualize_events.algorithms import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "from shapely.ops import voronoi_diagram\n",
    "from shapely.geometry import MultiPoint, Polygon, Point\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "T = load_dag()\n",
    "print(len(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECOMPUTE DISTANCE BETWEEN EVERY AE (just too much man, 184. GiB alone to store the result...)\n",
    "# S = T.keep_clinical_findings_and_body()\n",
    "# len(S)\n",
    "# S.add_parent_store()\n",
    "# nodes = S.nodes.values()\n",
    "# N = len(nodes)\n",
    "# S.root._attr_ancs()\n",
    "# anc_store = []\n",
    "# for i, n in enumerate(nodes):\n",
    "#     if i%10000==0: print(i/len(nodes))\n",
    "#     anc_store.append(n.leafs)\n",
    "# dist = np.zeros((N, N))\n",
    "# for i, anc1 in enumerate(anc_store):\n",
    "#     print(i)\n",
    "#     for j, anc2 in enumerate(anc_store[i+1:], i+1):\n",
    "# #         common = anc1.intersection(anc2)\n",
    "#         diff = anc1.symmetric_difference(anc2)\n",
    "#         #d = 1/len(common)\n",
    "# #         d = 1/(sum(a.depth for a in common)+1)\n",
    "#         d = len(diff)\n",
    "#         dist[i, j] = d\n",
    "#         dist[j, i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f698192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data('facts')['tox_drug_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef32d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_predictions(2793, predictor='ci_low') # frequency, ci_low, ci_upp\n",
    "P = T.set_predictions(preds, aggregate='sum')\n",
    "print(len(P))\n",
    "# 2793 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = P.compact_preds()\n",
    "C = C.set_predictions(preds, aggregate='sum')\n",
    "C.descendant_pred()\n",
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_events import HexMerge\n",
    "alg = HexMerge()\n",
    "alg.fit(C)\n",
    "fig = alg.make_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ab121",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = C\n",
    "t.add_parent_store()\n",
    "from itertools import combinations\n",
    "\n",
    "t.descendant_pred()\n",
    "pred_nodes = t.root.preds\n",
    "weights = dict()\n",
    "for n in t.nodes.values():\n",
    "    if n is t.root:\n",
    "        continue\n",
    "    for a, b in combinations(n.preds, 2):\n",
    "        if id(a) > id(b):\n",
    "            a, b = b, a\n",
    "        w = weights.get((a, b), 0)\n",
    "        weights[(a, b)] = w + 1 * n.depth\n",
    "print(weights)\n",
    "\n",
    "def nx_from_edge_weights(edge_weights):\n",
    "    if isinstance(edge_weights, dict):\n",
    "        edge_weights = edge_weights.items()\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from([(*key, {\"weight\": weight}) for key, weight in edge_weights])\n",
    "    return G\n",
    "\n",
    "# Could check if entire thing is planar or do binary/exponential search backwards\n",
    "sort_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)\n",
    "include = sort_weights[:4].copy()\n",
    "g = nx_from_edge_weights(include)\n",
    "deleted = 0\n",
    "added = 4\n",
    "for key, weight in sort_weights[4:]:\n",
    "    g.add_edge(*key, weight=weight)\n",
    "    is_planar, emb = nx.check_planarity(g)\n",
    "    if not is_planar:\n",
    "        g.remove_edge(*key)\n",
    "        deleted += 1\n",
    "        if deleted == 100:\n",
    "            break\n",
    "    else:\n",
    "        added += 1\n",
    "    \n",
    "print(f\"Deleted {deleted} from {len(weights)} edges, added {added}\")\n",
    "pos = nx.planar_layout(g)\n",
    "nx.draw(g, pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = None # Planar subdivision\n",
    "G_M = None # (weak) dual of M (planar triangulation)\n",
    "\n",
    "# Triangulate G_M (or it already is)\n",
    "# G_M has integer weighted nodes\n",
    "# drawing is a configuration C(v) of w(v) tiles for each vertex v\n",
    "# Guiding shapes.\n",
    "\n",
    "# --- Compute mosaic drawing\n",
    "# --- move and reshape\n",
    "# --- correct sizes of configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa63143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = list(C.nodes.values())\n",
    "N = len(C)\n",
    "indx_P_nodes, P_nodes = [], []\n",
    "for i, node in enumerate(nodes):\n",
    "    if (node.pred is not None and node.pred != 0):\n",
    "        indx_P_nodes.append(i)\n",
    "        P_nodes.append(node)\n",
    "\n",
    "# ------- CREATE CONSTRAINTS --------\n",
    "\n",
    "depths = C.get_depths()\n",
    "\n",
    "area_to_colors = []\n",
    "for d in range(len(depths)):\n",
    "    area_to_color = {n: [] for n in P_nodes}\n",
    "    V_d = depths[d]\n",
    "    for i, v in enumerate(V_d):\n",
    "        Rv = v.preds\n",
    "        for l in Rv:\n",
    "            area_to_color[l].append(i)\n",
    "    k = len(V_d)\n",
    "    for key,value in area_to_color.items():\n",
    "        if len(value) == 0:\n",
    "            value.append(k)\n",
    "            k+=1\n",
    "    area_to_colors.append(area_to_color)\n",
    "\n",
    "\n",
    "# ------- INITIAL POINT ASSIGNMENT --------\n",
    "anc_store = C.get_ancestors()\n",
    "\n",
    "dist = np.zeros((N, N))\n",
    "for i, anc1 in enumerate(anc_store):\n",
    "    for j, anc2 in enumerate(anc_store[i+1:], i+1):\n",
    "#         common = anc1.intersection(anc2)\n",
    "        diff = anc1.symmetric_difference(anc2)\n",
    "        #d = 1/len(common)\n",
    "#         d = 1/(sum(a.depth for a in common)+1)\n",
    "        d = len(diff) / (len(anc1) + len(anc2))\n",
    "        dist[i, j] = d\n",
    "        dist[j, i] = d\n",
    "\n",
    "\n",
    "similarity = dist[indx_P_nodes, :][:, indx_P_nodes]\n",
    "\n",
    "tsne = TSNE(metric=\"precomputed\",\n",
    "            perplexity=30,\n",
    "            early_exaggeration=10)\n",
    "embedding = tsne.fit_transform(similarity)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "embedding = scaler.fit_transform(embedding)\n",
    "\n",
    "# ------- IMPROVING POINT ASSIGNMENT --------\n",
    "drag = 0.01\n",
    "dt = 0.001\n",
    "dt_decay = 0.999\n",
    "dt_lower = 0.001\n",
    "contribution_pw_repel = 1\n",
    "contribution_edge_repel = 1\n",
    "\n",
    "total = contribution_pw_repel + contribution_edge_repel\n",
    "contribution_pw_repel /= total\n",
    "contribution_edge_repel /= total\n",
    "\n",
    "weights = np.array([p.pred for p in P_nodes])\n",
    "cross = np.power(weights.reshape(-1, 1)@weights.reshape(1, -1), 1.5)\n",
    "\n",
    "N_points = len(embedding)\n",
    "# move points away from eachother\n",
    "speed = np.zeros(embedding.shape)\n",
    "for epoch in range(10):\n",
    "    dt = dt * dt_decay\n",
    "    if dt < dt_lower:\n",
    "        print(\"Reached dt_lower, stopping\")\n",
    "        break\n",
    "#     within = (embedding[:, 0] < 1) & (embedding[:, 0] > -1) & (embedding[:, 1] < 1) & (embedding[:, 1] > -1)\n",
    "#     print(f\"Inside: {np.mean(within) * 100}%\")\n",
    "    \n",
    "    pw = pairwise_distances(embedding)\n",
    "    for i in range(N_points):\n",
    "        pw[i,i] = np.inf\n",
    "    min_pw = np.min(pw)\n",
    "#     print(f\"Smallest pw: {min_pw}\")\n",
    "    indx_nonzero = (pw == 0).nonzero()\n",
    "    for i, j in zip(*indx_nonzero):\n",
    "        embedding[i] += np.random.randn(2)\n",
    "        pw[i,j] = np.inf\n",
    "    min_pw = np.min(pw)\n",
    "\n",
    "    # pairwise repelling\n",
    "    # F = 1/d^2 * (u-v)/|u-v|\n",
    "    F_pw = np.divide(cross, pw * pw * pw) # TODO base this on pairwise weight!\n",
    "    assert F_pw.shape == pw.shape \n",
    "    move = np.tile(embedding.reshape(N_points, 1, 2), (1, N_points, 1)) - np.tile(embedding.reshape(1, N_points, 2), (N_points, 1, 1))\n",
    "    \n",
    "    F_pw = np.tile(F_pw.reshape(N_points, N_points, 1), (1, 1, 2)) * move\n",
    "    F_pw = np.sum(F_pw, axis=1)\n",
    "\n",
    "    \n",
    "    # repelling from edges\n",
    "    # direction: center, magnitude: ~ L5 norm ( not L2 so corners can get fuller )\n",
    "    # also cut off repelling at certain ratio\n",
    "    F_edge = np.zeros(embedding.shape)\n",
    "    magnitude = np.linalg.norm(embedding, ord=10, axis=1)\n",
    "    min_mag = 0.8\n",
    "    magnitude = magnitude * (magnitude > min_mag)\n",
    "    F_edge[:, 0] = (-embedding[:, 0]) * magnitude\n",
    "    F_edge[:, 1] = (-embedding[:, 1]) * magnitude\n",
    "    \n",
    "    # attracting based on similarity\n",
    "    # attracting based on visualization???\n",
    "\n",
    "    F_pw_mean = np.mean(np.linalg.norm(F_pw, axis=1))\n",
    "    F_pw = F_pw / F_pw_mean\n",
    "    F_edge_mean = np.mean(np.linalg.norm(F_edge, axis=1))\n",
    "    F_edge = F_edge / F_edge_mean\n",
    "    F_sum = F_pw * contribution_pw_repel + F_edge * contribution_edge_repel\n",
    "\n",
    "    # Hi\n",
    "    speed += F_sum * dt\n",
    "    \n",
    "    speed -= speed * drag\n",
    "    embedding += speed * dt\n",
    "\n",
    "within = (embedding[:, 0] < 1) & (embedding[:, 0] > -1) & (embedding[:, 1] < 1) & (embedding[:, 1] > -1)\n",
    "print(f\"Inside: {np.mean(within) * 100}%\")\n",
    "# ------- COMPUTE VORONOI --------\n",
    "points = MultiPoint(embedding.tolist())\n",
    "\n",
    "regions = voronoi_diagram(points)\n",
    "\n",
    "min_x = -1\n",
    "min_y = -1\n",
    "max_x = 1\n",
    "max_y = 1\n",
    "box = Polygon([[min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]])\n",
    "\n",
    "P_to_region = {}\n",
    "for i, node in enumerate(P_nodes):\n",
    "    coord = embedding[i]\n",
    "    p = Point(*coord)\n",
    "    found = False\n",
    "    for region in regions:\n",
    "        if region.contains(p):\n",
    "            assert not found\n",
    "            found = True\n",
    "            P_to_region[node] = region\n",
    "\n",
    "# ------- PLOT --------\n",
    "\n",
    "def path(coords):\n",
    "    svg = \"M\" + \"L\".join([str(px) + \",\" + str(py) for px,py in coords]) + \"Z\" # could do coords[:-1] I think\n",
    "    return svg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_choices = range(len(depths))#[0,1,2,3,4,5,10,15,20]\n",
    "figs = []\n",
    "for subplot_i, d in enumerate(depth_choices):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Update axes properties\n",
    "    fig.update_xaxes(\n",
    "        showticklabels=False,\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        showticklabels=False,\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        scaleanchor = \"x\",\n",
    "        scaleratio = 1,\n",
    "    )\n",
    "\n",
    "    shapes = []\n",
    "    colors = plotly.colors.sample_colorscale(colorscale='Turbo', samplepoints=k)\n",
    "    np.random.shuffle(colors)\n",
    "    for i, node_with_pred in enumerate(P_nodes):\n",
    "        region = P_to_region[node_with_pred]\n",
    "        poly = region.intersection(box)\n",
    "        polygon = [p for p in poly.exterior.coords]\n",
    "    #     print(polygon)\n",
    "    #     plt.fill(*zip(*polygon), alpha=0.4)\n",
    "\n",
    "        assignments = area_to_colors[d][node_with_pred]\n",
    "        color = colors[np.random.choice(assignments).item()]\n",
    "        shapes.append(\n",
    "            dict(\n",
    "                type=\"path\",\n",
    "                path=path(polygon),\n",
    "                fillcolor=color,\n",
    "                line_color=color,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # Add shapes\n",
    "    fig.update_layout(\n",
    "        shapes=shapes,\n",
    "        xaxis_range=[-1,1],\n",
    "        yaxis_range=[-1,1],\n",
    "        hovermode=\"closest\"\n",
    "    )\n",
    "\n",
    "    figs.append(fig)\n",
    "\n",
    "for depth, fig in zip(depth_choices, figs):\n",
    "    print(\"Depth of \", depth)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = voronoi_plot_2d(vor)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = C.copy(init=False)\n",
    "tree = tree.set_predictions(preds)\n",
    "tree.add_parent_store()\n",
    "print(len(tree))\n",
    "# tree.splice(keep_constraint = lambda n: n.pred_agg >= 0.01)\n",
    "\n",
    "tree.attr_label()\n",
    "edges = [\n",
    "    (node.name, child.name) for node in tree.nodes.values() for child in node.children\n",
    "]\n",
    "g = nx.DiGraph()\n",
    "g.add_edges_from(edges)\n",
    "nodes = list(tree.nodes.values())\n",
    "#draw_nodes = [n for n in nodes if n.pred_agg > 0.01]\n",
    "# draw_nodes = nodes\n",
    "\n",
    "N = len(nodes)\n",
    "\n",
    "anc_store = tree.get_ancestors()\n",
    "\n",
    "dist = np.zeros((N, N))\n",
    "for i, anc1 in enumerate(anc_store):\n",
    "    for j, anc2 in enumerate(anc_store[i+1:], i+1):\n",
    "#         common = anc1.intersection(anc2)\n",
    "        diff = anc1.symmetric_difference(anc2)\n",
    "        #d = 1/len(common)\n",
    "#         d = 1/(sum(a.depth for a in common)+1)\n",
    "        d = len(diff)\n",
    "        dist[i, j] = d\n",
    "        dist[j, i] = d\n",
    "\n",
    "print(\"computing draw nodes\")\n",
    "# draw_nodes = nodes\n",
    "# draw_nodes = representative(tree, 50, score=lambda w, d: w * 1/(1.9**d))\n",
    "draw_nodes = representative(tree, 50, score=lambda w, d: w * 1/(1+d))\n",
    "draw_nodes = greedy_plus(tree, 50)\n",
    "print(\"draw nodes computed\")\n",
    "        \n",
    "tsne = TSNE(metric=\"precomputed\",\n",
    "            perplexity=30,\n",
    "            early_exaggeration=10)\n",
    "embedding = tsne.fit_transform(dist)\n",
    "pos = {n.name: tuple(embedding[i]) for i, n in enumerate(nodes) if n in nodes}\n",
    "\n",
    "scale = max(p[0] for p in pos.values()) - min(p[0] for p in pos.values())\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.gca()\n",
    "\n",
    "SCALE = 10\n",
    "AGG_FAC = 1.\n",
    "\n",
    "f_pred = scale * SCALE\n",
    "f_agg = f_pred * AGG_FAC\n",
    "\n",
    "def node_size(node):\n",
    "    s = 1\n",
    "    if node.pred is not None:\n",
    "        s += node.pred * f_pred\n",
    "    elif node.pred_agg is not None:\n",
    "        s += node.pred_agg * f_agg\n",
    "    return s\n",
    "\n",
    "def node_color(node):\n",
    "    if node.pred is not None:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"blue\"\n",
    "\n",
    "draw_nodes_names = [n.name for n in draw_nodes]\n",
    "# edges = [edge for edge in g.edges() if (edge[0] in draw_nodes_names and edge[1] in draw_nodes_names)]\n",
    "edges = []\n",
    "# for name, node in tree.nodes.items():\n",
    "#     for child in node.children:\n",
    "#         c_name = child.name\n",
    "#         edges.append((name, c_name))\n",
    "\n",
    "width = []\n",
    "for edge in edges:\n",
    "    a = pos[edge[0]]\n",
    "    b = pos[edge[1]]\n",
    "    dist = np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "    width.append(1/(dist))\n",
    "    \n",
    "nx.draw_networkx(g,\n",
    "        pos=pos,\n",
    "        nodelist=draw_nodes_names,\n",
    "        edgelist=edges,\n",
    "        node_size=[node_size(n) for n in draw_nodes],\n",
    "        node_color=[node_color(n) for n in draw_nodes],\n",
    "        labels={n.name: (n.label if n.pred is not None and n.pred > 1.0 else \"\") for n in draw_nodes},\n",
    "        width=0.2,\n",
    "        ax=ax)\n",
    "\n",
    "# edges = g.edges()\n",
    "\n",
    "# nx.draw_networkx_edges(g, pos=pos, arrows=False, ax=ax, width=width)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde7c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe76749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, TreeStyle, NodeStyle, faces, AttrFace, CircleFace\n",
    "\n",
    "def layout(node):\n",
    "    if hasattr(node, 'f'):\n",
    "        frequency = float(node.f)\n",
    "        lowerbound = float(node.lb)\n",
    "        \n",
    "        C = CircleFace(radius=frequency * 100, color=\"Red\", style=\"sphere\")\n",
    "        C.opacity=lowerbound\n",
    "        faces.add_face_to_node(C, node, 0, position=\"float\")\n",
    "\n",
    "    faces.add_face_to_node(AttrFace(\"name\"), node, column=0)\n",
    "\n",
    "# Create an empty TreeStyle\n",
    "ts = TreeStyle()\n",
    "\n",
    "# Set our custom layout function\n",
    "ts.layout_fn = layout\n",
    "\n",
    "# Draw a tree\n",
    "ts.mode = \"c\"\n",
    "\n",
    "# We will add node names manually\n",
    "ts.show_leaf_name = True\n",
    "# Show branch data\n",
    "ts.show_branch_length = False\n",
    "ts.show_branch_support = False\n",
    "\n",
    "\n",
    "# Getting the tree\n",
    "threshold = 0.03\n",
    "G = C.copy(init=False)\n",
    "G = G.set_predictions(preds)\n",
    "print(len(G))\n",
    "G = G.filter(keep_constraint = lambda n: n.pred_agg >= threshold)\n",
    "print(len(G))\n",
    "G.splice(keep_constraint = lambda n : len(n.children) != 1)\n",
    "print(len(G))\n",
    "# G.make_tree()\n",
    "G.attr_label()\n",
    "t = G.get_newick()\n",
    "t = Tree(t, format=8, quoted_node_names=True)\n",
    "\n",
    "# t.show(tree_style=ts)\n",
    "t.render(\"mytree.png\", w=183, units=\"mm\", dpi=1000, tree_style=ts)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96546980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([\n",
    "    nx.is_tree(G),\n",
    "    nx.is_forest(G),\n",
    "    nx.is_arborescence(G),\n",
    "    nx.is_branching(G),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5567d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01489dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(c) for c in T.root.children[0].children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182590c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing two nodes\n",
    "C.add_parent_store()\n",
    "\n",
    "Is = []\n",
    "for I in [0,2]:\n",
    "    i = 0\n",
    "    for k in C.nodes:\n",
    "        n = C.nodes[k]\n",
    "        if len(n.children) == 0:\n",
    "            print(n)\n",
    "            if i == I:\n",
    "                x = n\n",
    "                break\n",
    "            i += 1\n",
    "    Is.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different trees\n",
    "T.attr_label()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), gridspec_kw={'width_ratios': [0.7, 3]})\n",
    "\n",
    "plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(T.nodes[Is[0].name], T, ax=axs[0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"example_{Is[0]}.pdf\", dpi=600)\n",
    "\n",
    "# plt.figure(figsize=(9,7))\n",
    "# plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(T.nodes[Is[1].name], T, ax=axs[1])\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f\"examples.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5846cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different trees\n",
    "P.add_parent_store()\n",
    "P.attr_label()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), gridspec_kw={'width_ratios': [0.7, 3]})\n",
    "\n",
    "plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(P.nodes[Is[0].name], T, ax=axs[0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"example_{Is[0]}.pdf\", dpi=600)\n",
    "\n",
    "# plt.figure(figsize=(9,7))\n",
    "# plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(P.nodes[Is[1].name], T, ax=axs[1])\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f\"examples.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66374da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different trees\n",
    "C.add_parent_store()\n",
    "C.attr_label()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10), gridspec_kw={'width_ratios': [0.7, 3]})\n",
    "\n",
    "plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(C.nodes[Is[0].name], T, ax=axs[0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"example_{Is[0]}.pdf\", dpi=600)\n",
    "\n",
    "# plt.figure(figsize=(9,7))\n",
    "# plt.xlim([-1.3, 1.3])\n",
    "draw_subgraph_to_leaf(C.nodes[Is[1].name], T, ax=axs[1])\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f\"examples.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee852b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.nodes[4224004].parents[0].parents[0].parents[0].parents[0].parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec44923",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in T.nodes[4224004].ancestors():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192facc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A={0,1}x[0,n]x[0,m] -> P\n",
    "# 2nm places -> P\n",
    "\n",
    "# nodes_df = pd.DataFrame({'name':[0,1,2,3,4,5],'label':[0,1,2,3,4,5]}).set_index('name')\n",
    "# edges_df = pd.DataFrame({'parent':[0, 0, 0, 1, 2, 3,1],'child':[1, 2, 3, 4, 4, 4,5]})\n",
    "# diamond_tail = DAG(nodes_df, edges_df)\n",
    "# predictions = pd.Series([1, 1], index=[4, 5])\n",
    "# t = diamond_tail.set_predictions(predictions)\n",
    "\n",
    "# ---------- PARAMS\n",
    "t = C\n",
    "\n",
    "target_hexes = 100\n",
    "kmax = 0\n",
    "same_leaf_factor = 1\n",
    "adjacency_factor = 1\n",
    "distance_factor = 100\n",
    "hexes_scaling = lambda x : x\n",
    "temperature = lambda k, kmax: (1 - (k)/kmax) ** 2 / 20 #.1/np.exp(k / 100).item()\n",
    "acceptance_function = lambda cost_diff, T, rv: cost_diff < 0 or np.exp((-cost_diff+0.01)/T) >= rv\n",
    "quantile = .0\n",
    "moved_running_avg_window = 10000\n",
    "MOVED_LOWERBOUND = 0.03\n",
    "# hexes_scaling = lambda x : 1 + np.sqrt(x).item() # PARAM.\n",
    "\n",
    "\n",
    "# ---------- PLOTTING PARAMS\n",
    "angle = - np.pi / 6\n",
    "radius = 1/np.sqrt(3)\n",
    "angles = np.array([angle + k * (np.pi/3) for k in range(6)])\n",
    "x_hex = radius * np.cos(angles)\n",
    "y_hex = radius * np.sin(angles)\n",
    "x_width = np.amax(x_hex) - np.amin(x_hex)\n",
    "y_width = np.amax(y_hex) - np.amin(y_hex)\n",
    "\n",
    "def center(row, col):\n",
    "    cx = (col * radius * 1.5)\n",
    "    cy = np.sqrt(3) * row\n",
    "    if col % 2 == 1:\n",
    "        cy = cy + np.sqrt(3) * 0.5\n",
    "    return cx, cy\n",
    "\n",
    "def cartesian(a, r, c):\n",
    "    return (\n",
    "        a/2 + c,\n",
    "        np.sqrt(3) * (a/2 + r)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "n = int(np.sqrt(target_hexes) // 2)\n",
    "m = int(np.sqrt(target_hexes))\n",
    "assert 2 * n * m <= target_hexes\n",
    "\n",
    "scaled = [hexes_scaling(P_node.pred) for P_node in t.nodes.values() if P_node.pred is not None]\n",
    "sum_scaled = sum(scaled)\n",
    "to_place = []\n",
    "\n",
    "nodes = list(t.nodes.values())\n",
    "N = len(t)\n",
    "indx_P_nodes, P_nodes = [], []\n",
    "for i, node in enumerate(nodes):\n",
    "    if (node.pred is not None and node.pred != 0):\n",
    "        hexes = int(np.floor(hexes_scaling(node.pred) / sum_scaled * (2*n*m)).item())\n",
    "        if hexes <= 0:\n",
    "            continue\n",
    "        indx_P_nodes.append(i)\n",
    "        P_nodes.append(node)\n",
    "        for _ in range(hexes):\n",
    "            to_place.append(len(P_nodes) - 1)\n",
    "P_N = len(P_nodes)\n",
    "\n",
    "\n",
    "# to_place = [i for i, P_node in enumerate(P_nodes) for _ in range(int(np.floor(scaled[i] / sum_scaled * (2*n*m)).item()))]\n",
    "\n",
    "assert 2 * n * m >= len(to_place)\n",
    "\n",
    "t.add_parent_store()\n",
    "from itertools import combinations\n",
    "t.descendant_pred()\n",
    "pred_nodes = t.root.preds\n",
    "weights = dict()\n",
    "for node in t.nodes.values():\n",
    "    if node is t.root:\n",
    "        continue\n",
    "    significant_preds = [pred for pred in node.preds if pred in P_nodes]\n",
    "    for a, b in combinations(significant_preds, 2):\n",
    "        if a == b:\n",
    "            assert False\n",
    "        if id(a) > id(b):\n",
    "            a, b = b, a\n",
    "        w = weights.get((a, b), 0)\n",
    "        weights[(a, b)] = w + 1 * node.depth\n",
    "\n",
    "total_weight = sum(weights.values())\n",
    "\n",
    "for k, v in weights.items():\n",
    "    weights[k] = (v / total_weight) * adjacency_factor\n",
    "\n",
    "# weight all adjacencies and all transitive stuff the same    \n",
    "for P_node in P_nodes:\n",
    "    weights[(P_node, P_node)] = same_leaf_factor / P_N\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(P_nodes)}\n",
    "new_weights = dict()\n",
    "for k, v in weights.items():\n",
    "    n1, n2 = k\n",
    "    n1, n2 = node_to_idx[n1], node_to_idx[n2]\n",
    "    new_weights[(n1, n2)] = v\n",
    "\n",
    "weights = new_weights\n",
    "\n",
    "# ------- DESIRED LOCATION --------\n",
    "anc_store = t.get_ancestors()\n",
    "\n",
    "dist = np.zeros((N, N))\n",
    "for i, anc1 in enumerate(anc_store):\n",
    "    for j, anc2 in enumerate(anc_store[i+1:], i+1):\n",
    "#         common = anc1.intersection(anc2)\n",
    "        diff = anc1.symmetric_difference(anc2)\n",
    "        #d = 1/len(common)\n",
    "#         d = 1/(sum(a.depth for a in common)+1)\n",
    "        d = len(diff) / (len(anc1) + len(anc2))\n",
    "        dist[i, j] = d\n",
    "        dist[j, i] = d\n",
    "\n",
    "similarity = dist[indx_P_nodes, :][:, indx_P_nodes]\n",
    "\n",
    "tsne = TSNE(metric=\"precomputed\",\n",
    "            perplexity=30,\n",
    "            early_exaggeration=10)\n",
    "embedding = tsne.fit_transform(similarity)\n",
    "\n",
    "x_min, y_min = cartesian(0, 0, 0)\n",
    "x_max, y_max = cartesian(1, n, m)\n",
    "# TODO might need to offset\n",
    "x_scaler = MinMaxScaler(feature_range=(x_min,x_max))\n",
    "y_scaler = MinMaxScaler(feature_range=(y_min,y_max))\n",
    "embedding[:, 0] = x_scaler.fit_transform(embedding[:, 0].reshape(-1, 1)).reshape(-1)\n",
    "embedding[:, 1] = y_scaler.fit_transform(embedding[:, 1].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# to_01_scaler = MinMaxScaler(feature_range=(0,1)).fit(embedding) # distorts distances because figure does not have asp ratio of 1\n",
    "\n",
    "def neighbors(a, r, c):\n",
    "    # interesting fact: if a and b are neighbors, and a is the x-th neighbor of b, then b is the (x+3%6)-th neighbor of a\n",
    "    return (\n",
    "        (a, r, (c+1) % m),\n",
    "        (1-a, (r-(1-a)) % n, (c+a) % m),\n",
    "        (1-a, (r-(1-a)) % n, (c-(1-a)) % m),\n",
    "        (a, r, (c-1) % m),\n",
    "        (1-a, (r+a) % n, (c-(1-a)) % m),\n",
    "        (1-a, (r+a) % n, (c+a) % m)\n",
    "    )\n",
    "\n",
    "def cost(assignment):\n",
    "    cost_matrix_adj = np.zeros((2, n, m, 6))\n",
    "    it = np.nditer(assignment, flags=['multi_index'])\n",
    "    for x in it:\n",
    "        if x < 0:\n",
    "            continue\n",
    "        for neighbor_idx, neighbor in enumerate(neighbors(*it.multi_index)): # can make more eff due to symmetry \n",
    "            y = assignment[neighbor]\n",
    "            if y < 0:\n",
    "                continue\n",
    "            w = weights.get((x.item(), y), 0)\n",
    "            if w == 0:\n",
    "                w = weights.get((y, x.item()), 0) # only one will exist atm\n",
    "            if w != 0:\n",
    "                cost_matrix_adj[(*it.multi_index, neighbor_idx)] = -w\n",
    "    \n",
    "    cost_matrix_dis = np.zeros((2, n, m))\n",
    "    it = np.nditer(assignment, flags=['multi_index'])\n",
    "    for x in it:\n",
    "        if x < 0:\n",
    "            continue\n",
    "        tile_x, tile_y = cartesian(*it.multi_index)\n",
    "        xx, xy = embedding[x].tolist()\n",
    "        d = ((xx - tile_x)/(2*n-1)) ** 2 + ((xy - tile_y)/(m-1)) ** 2\n",
    "        cost_matrix_dis[it.multi_index] = d\n",
    "    cost_matrix_dis *= distance_factor\n",
    "\n",
    "    cost_matrix_adj_sum = np.sum(cost_matrix_adj, axis=3)\n",
    "    cost_agg = np.sum(cost_matrix_adj_sum) + np.sum(cost_matrix_dis)\n",
    "    return cost_agg, cost_matrix_adj, cost_matrix_adj_sum, cost_matrix_dis\n",
    "\n",
    "# def random_neighbor(s):\n",
    "#     # SWITCHEROO\n",
    "# #     x = np.random.choice(2), np.random.choice(n), np.random.choice(m)\n",
    "# #     y = neighbors(*x)[np.random.choice(3)]\n",
    "# #     s_new = s.copy()\n",
    "# #     s_new[x], s_new[y] = s_new[y], s_new[x]\n",
    "#     # RANDOM ASSIGNMENT\n",
    "#     s_new = s.copy()\n",
    "#     x = np.random.choice(2), np.random.choice(n), np.random.choice(m)\n",
    "#     s_new[x] = np.random.choice(P_N+1) - 1\n",
    "#     return s_new\n",
    "     \n",
    "# s = np.random.choice(P_N, replace=True, size=(2, n, m))\n",
    "\n",
    "def cost_x(s, x):\n",
    "    assignment = s[x]\n",
    "    if assignment < 0:\n",
    "        return [0] * 6, 0\n",
    "    new_cost_x_neighbors = []\n",
    "    for neighbor in neighbors(*x):\n",
    "        neighbor_assignment = s[neighbor]\n",
    "        if neighbor_assignment < 0:\n",
    "            w = 0\n",
    "        else:\n",
    "            w = weights.get((assignment, neighbor_assignment), 0)\n",
    "            if w == 0:\n",
    "                w = weights.get((neighbor_assignment, assignment), 0)\n",
    "        new_cost_x_neighbors.append(-w)\n",
    "\n",
    "    xx, xy = cartesian(*x)\n",
    "    yx, yy = embedding[assignment].tolist()\n",
    "    d = ((xx - yx)/(2*n-1)) ** 2 + ((xy - yy)/(m-1)) ** 2\n",
    "    d *= distance_factor\n",
    "    return new_cost_x_neighbors, d\n",
    "\n",
    "def set_cost_x(s, cost_matrix, cost_matrix_sum, x, cost_neighbors_x):\n",
    "    # own\n",
    "    cost_matrix[x] = cost_neighbors_x\n",
    "    cost_matrix_sum[x] = np.sum(cost_matrix[x])\n",
    "    # others'\n",
    "    for neighbor_idx, neighbor in enumerate(neighbors(*x)):\n",
    "        self_idx = (neighbor_idx + 3) % 6\n",
    "        cost_matrix[(*neighbor, self_idx)] = cost_neighbors_x[neighbor_idx]\n",
    "        cost_matrix_sum[neighbor] = np.sum(cost_matrix[neighbor])\n",
    "\n",
    "def random_grid_point():\n",
    "    return (np.random.choice(2), np.random.choice(n), np.random.choice(m))\n",
    "\n",
    "# RANDOM LAYOUT\n",
    "# for _ in range(2 * n * m - len(to_place)):\n",
    "#     to_place.append(-1)\n",
    "# s = np.array(to_place)\n",
    "# np.random.shuffle(s)\n",
    "# s = s.reshape(2, n, m)\n",
    "\n",
    "# TODO better initialization - Greedy?\n",
    "np.random.shuffle(to_place)\n",
    "s = np.ones((2, n, m), dtype=int) * -1\n",
    "# maintain a heap of: option -> max. cost reduction\n",
    "\n",
    "def marginal_cost(s, x, assign):\n",
    "    assert s[x] < 0\n",
    "    s[x] = assign\n",
    "    new_cost_x_neighbors, distance_cost = cost_x(s, x)\n",
    "    marginal = 2 * sum(new_cost_x_neighbors) + distance_cost\n",
    "    s[x] = -1\n",
    "    return marginal\n",
    "\n",
    "to_place_set = set(to_place)\n",
    "options = np.zeros((2, n, m, P_N))\n",
    "for a in (0,1):\n",
    "    for r in range(n):\n",
    "        for c in range(m):\n",
    "            for assign in to_place_set:\n",
    "                options[a, r, c, assign] = (\n",
    "                    marginal_cost(s, (a, r, c), assign)\n",
    "                )\n",
    "\n",
    "to_place_still = {assign: to_place.count(assign) for assign in to_place_set}\n",
    "to_place_still_total = len(to_place)\n",
    "while to_place_still_total > 0:\n",
    "    a, r, c, assign = np.unravel_index(np.argmin(options, axis=None), options.shape)\n",
    "    s[(a, r, c)] = assign\n",
    "    options[a, r, c, :] = np.infty\n",
    "    to_place_still[assign] -= 1\n",
    "    to_place_still_total -= 1\n",
    "    if to_place_still_total == 0:\n",
    "        break\n",
    "    if to_place_still[assign] == 0:\n",
    "        options[:, :, :, assign] = np.infty\n",
    "        to_place_set.remove(assign)\n",
    "    for neighbor in neighbors(a, r, c):\n",
    "        if s[neighbor] < 0:\n",
    "            for assign in to_place_set:\n",
    "                if options[a, r, c, assign] != np.infty:\n",
    "                    options[a, r, c, assign] = (\n",
    "                        marginal_cost(s, (a, r, c), assign)\n",
    "                    )  \n",
    "                    \n",
    "cost_s, cost_matrix_s, cost_matrix_s_sum, cost_matrix_s_distances = cost(s)\n",
    "moved = 0\n",
    "moved_running_avg = 0.\n",
    "movable_points = None\n",
    "for k in range(kmax):\n",
    "    if k%1000==0:\n",
    "        print(f\"Cost: {np.sum(cost_matrix_s_sum) + np.sum(cost_matrix_s_distances)}. Running average % moved: {moved_running_avg}\")\n",
    "    T = temperature(k, kmax)\n",
    "    # random neighbor testing\n",
    "    if k % 10 == 0:\n",
    "        moveable_points = np.arange(2*n*m)[cost_matrix_s_sum.reshape(-1) >= np.quantile(cost_matrix_s_sum, quantile)]\n",
    "    x, y = np.random.choice(moveable_points, replace=False, size=2).tolist()\n",
    "    x = (x//(n*m), (x//m)%n, x%m)\n",
    "    y = (y//(n*m), (y//m)%n, y%m)\n",
    "    if x == y: continue\n",
    "    #\n",
    "    old_assignment_x = s[x]\n",
    "    old_assignment_y = s[y]\n",
    "    old_cost_x = np.sum(cost_matrix_s[x]) + cost_matrix_s_distances[x]\n",
    "    old_cost_y = np.sum(cost_matrix_s[y]) + cost_matrix_s_distances[y]\n",
    "    \n",
    "#     new_assignment = np.random.choice(P_N+1) - 1 # random choice of neighbor (different color in that hex)\n",
    "    s[x], s[y] = old_assignment_y, old_assignment_x\n",
    "    new_cost_x_neighbors, distance_cost_x = cost_x(s, x)\n",
    "    new_cost_y_neighbors, distance_cost_y = cost_x(s, y)\n",
    "    \n",
    "    cost_diff = 2 * (\n",
    "        sum(new_cost_x_neighbors) + distance_cost_x - old_cost_x\n",
    "        + sum(new_cost_y_neighbors) + distance_cost_y - old_cost_y\n",
    "    ) # times TWO because of double counting adjacency TODO half_neighbors?\n",
    "    acceptance = acceptance_function(cost_diff, T, np.random.uniform())\n",
    "    if acceptance:\n",
    "        moved += 1\n",
    "        just_moved = True\n",
    "        set_cost_x(s, cost_matrix_s, cost_matrix_s_sum, x, new_cost_x_neighbors)\n",
    "        set_cost_x(s, cost_matrix_s, cost_matrix_s_sum, y, new_cost_y_neighbors)\n",
    "        cost_matrix_s_distances[x] = distance_cost_x\n",
    "        cost_matrix_s_distances[y] = distance_cost_y\n",
    "    else:\n",
    "        just_moved = False\n",
    "        s[x] = old_assignment_x\n",
    "        s[y] = old_assignment_y\n",
    "#     print(x, y)\n",
    "    moved_running_avg = (\n",
    "        (min(moved_running_avg_window-1, k) * moved_running_avg + just_moved)\n",
    "        /min(moved_running_avg_window, k+1)\n",
    "    )\n",
    "    if moved_running_avg <= MOVED_LOWERBOUND and k > moved_running_avg_window:\n",
    "        print(f\"Early stop at k={k}\")\n",
    "        break\n",
    "#     calc = cost(s)\n",
    "#     assert (cost_matrix_s == calc[1]).all()\n",
    "#     assert (cost_matrix_s_sum == calc[2]).all()\n",
    "#     assert (cost_matrix_s_distances == calc[3]).all()\n",
    "print(f\"Moved {moved} out of {k} iters\")\n",
    "\n",
    "# PSEUDOCODE sim annealing\n",
    "# Let s = s0\n",
    "# For k = 0 through kmax (exclusive):\n",
    "\n",
    "#     T ← temperature( 1 - (k+1)/kmax )\n",
    "#     Pick a random neighbour, snew ← neighbour(s)\n",
    "#     If P(E(s), E(snew), T) ≥ random(0, 1):\n",
    "#         s ← snew\n",
    "\n",
    "# Output: the final state \n",
    "\n",
    "assignment = s\n",
    "\n",
    "# locations = [center(i, j) for i in range(10) for j in range(10)]\n",
    "\n",
    "def svg_path(xc, yc, radius_modifier = 1.):\n",
    "    return \"M\" + \"L\".join([str(px) + \",\" + str(py) for px,py in zip(xc + x_hex * radius_modifier, yc + y_hex * radius_modifier)]) + \"Z\"\n",
    "\n",
    "def path(xc, yc, radius_modifier = 1.):\n",
    "    x_coords = (xc + x_hex * radius_modifier).tolist()\n",
    "    x_coords.append(x_coords[0])\n",
    "    y_coords = (yc + y_hex * radius_modifier).tolist()\n",
    "    y_coords.append(y_coords[0])\n",
    "    return x_coords, y_coords\n",
    "\n",
    "\n",
    "P_nodes_to_grid = {P_node: [] for P_node in P_nodes}\n",
    "\n",
    "it = np.nditer(assignment, flags=['multi_index'])\n",
    "for x in it:\n",
    "    if x >= 0:\n",
    "        P_nodes_to_grid[P_nodes[x]].append(it.multi_index)\n",
    "\n",
    "t.attr_label()\n",
    "depths = t.get_depths()    \n",
    "\n",
    "colors_required = P_N + max(len(V_d) for V_d in depths)\n",
    "\n",
    "colors = plotly.colors.sample_colorscale(colorscale='Turbo', samplepoints=colors_required)\n",
    "np.random.shuffle(colors)\n",
    "\n",
    "# max_pred = max([P_node.pred for P_node in P_nodes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88894aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Update axes properties\n",
    "fig.update_xaxes(\n",
    "    showticklabels=False,\n",
    "    showgrid=False,\n",
    "    zeroline=False,\n",
    "    range=[x_min - radius, x_max + radius]\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    showticklabels=False,\n",
    "    showgrid=False,\n",
    "    zeroline=False,\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "    range=[y_min - radius, y_max + radius]\n",
    ")\n",
    "\n",
    "# ------- CREATE CONSTRAINTS --------\n",
    "P_node_to_color = {P_node: color for P_node, color in zip(P_nodes, colors)} # shouldn't matter that colors is longer\n",
    "d_P_node_occupancy = [{P_node: [] for P_node in P_nodes} for _ in depths]\n",
    "v_to_color = dict()\n",
    "for d in range(len(depths)):\n",
    "    V_d = depths[d]\n",
    "    # matrix of shape (V_d)\n",
    "    # largest colors maintain.\n",
    "    area_coverage = np.zeros(len(V_d))\n",
    "    for i, v in enumerate(V_d):\n",
    "        Rv = [pred for pred in v.preds if pred in P_nodes]\n",
    "        coverage = []\n",
    "        for P_node in Rv:\n",
    "            d_P_node_occupancy[d][P_node].append(v)\n",
    "            coverage += P_nodes_to_grid[P_node]\n",
    "        area_coverage[i] = len(set(coverage))\n",
    "    indxs = np.flip(np.argsort(area_coverage))\n",
    "    \n",
    "    remaining_colors = set(colors)\n",
    "    for indx in indxs:\n",
    "        v = V_d[indx]\n",
    "        Rv = [pred for pred in v.preds if pred in P_nodes]\n",
    "        max_col = -1\n",
    "        max_size = -1\n",
    "        for P_node in Rv:\n",
    "            size = len(P_nodes_to_grid[P_node])\n",
    "            col = P_node_to_color[P_node]\n",
    "            if size > max_size and col in remaining_colors:\n",
    "                max_size = size\n",
    "                max_col = col\n",
    "        if max_col == -1:\n",
    "            max_col = remaining_colors.pop()\n",
    "        else:\n",
    "            remaining_colors.remove(max_col)\n",
    "        v_color = max_col\n",
    "        v_to_color[v] = v_color\n",
    "\n",
    "\n",
    "\n",
    "disc = 100000\n",
    "def simplify_grid_coords(grid_coords):\n",
    "#     edges = [\n",
    "#         grid_coord for grid_coord in grid_coords if not all(\n",
    "#             neighbor in grid_coords for neighbor in neighbors(*grid_coord)\n",
    "#         )\n",
    "#     ]\n",
    "#     while len(edges) != 0\n",
    "    segments = dict()\n",
    "    for grid_coord in grid_coords:\n",
    "        cart = cartesian(*grid_coord)\n",
    "        x_coords, y_coords = path(*cart)\n",
    "        for i, neigh in enumerate(neighbors(*grid_coord)):\n",
    "            if neigh not in grid_coords:\n",
    "                x1, x2 = x_coords[i:i+2]\n",
    "                y1, y2 = y_coords[i:i+2]\n",
    "                x1 = int(round(x1 * disc))\n",
    "                x2 = int(round(x2 * disc))\n",
    "                y1 = int(round(y1 * disc))\n",
    "                y2 = int(round(y2 * disc))\n",
    "                adj = segments.get((x1, y1), [])\n",
    "                adj.append((x2, y2))\n",
    "                segments[(x1, y1)] = adj\n",
    "    \n",
    "    prev_point = list(segments.keys())[0]\n",
    "    cycles = []\n",
    "    current_cycle = [prev_point]\n",
    "    while True:\n",
    "        next_points = segments.get(prev_point, None)\n",
    "        if next_points is None:\n",
    "            cycles.append(current_cycle)\n",
    "            if len(segments) == 0:\n",
    "                break\n",
    "            prev_point = list(segments.keys())[0]\n",
    "            current_cycle = []\n",
    "        elif len(next_points) == 1:\n",
    "            del segments[prev_point]\n",
    "            prev_point = next_points[0]\n",
    "        else:\n",
    "            prev_point = next_points.pop() # it matters which we pop!?\n",
    "        \n",
    "        current_cycle.append(prev_point)\n",
    "    x_coord, y_coord = [], []\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        if i > 0:\n",
    "            x_coord.append(None)\n",
    "            y_coord.append(None)\n",
    "        for x_co, y_co in cycle:\n",
    "            x_coord.append(x_co / disc)\n",
    "            y_coord.append(y_co / disc)\n",
    "    return x_coord, y_coord\n",
    "\n",
    "v_to_trace = dict()\n",
    "for d, V_d in enumerate(depths):\n",
    "    for v in V_d:\n",
    "        Rv = [pred for pred in v.preds if pred in P_nodes]\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "        for P_node in Rv:\n",
    "#     color = colors[node_colors[0]]\n",
    "            occupancy = d_P_node_occupancy[d][P_node]\n",
    "            order = occupancy.index(v)\n",
    "            radius = 1 - (order / len(occupancy))\n",
    "            for j, grid_coord in enumerate(P_nodes_to_grid[P_node]):\n",
    "                if j > 0:\n",
    "                    x_coords.append(None)\n",
    "                    y_coords.append(None)\n",
    "                location = cartesian(*grid_coord)\n",
    "                x_coord, y_coord = path(*location, radius_modifier = radius)\n",
    "#                 if len(occupancy) == 1:\n",
    "#                     pass\n",
    "#                 elif len(occupancy) in [2, 3]:\n",
    "#                     slices = len(occupancy)\n",
    "#                     slice_size = 6 // len(occupancy)\n",
    "#                     idx = order * slice_size\n",
    "#                     x_coord = x_coord[idx:idx + slice_size+1]\n",
    "#                     y_coord = y_coord[idx:idx + slice_size+1]\n",
    "#                     x_coord.append(location[0])\n",
    "#                     y_coord.append(location[1])\n",
    "#                     x_coord.append(x_coord[0])\n",
    "#                     y_coord.append(y_coord[0])\n",
    "#                 else:\n",
    "#                     raise ValueError(\"hi\")\n",
    "                x_coords.extend(x_coord)\n",
    "                y_coords.extend(y_coord)\n",
    "        v_to_trace[v] = len(fig.data)\n",
    "        fig.add_trace(go.Scatter(x=x_coords, y=y_coords, fill=\"toself\", mode=\"text\", fillcolor=v_to_color[v], name=v.label, visible=False)) # mode=\"lines\"\n",
    "\n",
    "nodes_left = sum(len(V_d) for V_d in depths)\n",
    "nodes_seen = 0  \n",
    "steps = []\n",
    "for d, V_d in enumerate(depths):\n",
    "    nodes_this_layer = len(V_d)\n",
    "    nodes_left -= nodes_this_layer\n",
    "    visible = [False] * nodes_seen + [True] * nodes_this_layer + [False] * nodes_left\n",
    "    nodes_seen += nodes_this_layer\n",
    "    for P_node in P_nodes:\n",
    "        if P_node.depth < d:\n",
    "            visible[v_to_trace[P_node]] = True\n",
    "\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": visible},\n",
    "              {\"title\": \"Depth: \" + str(i)}],  # layout attribute\n",
    "    )\n",
    "    steps.append(step)\n",
    "        \n",
    "sliders = [dict(\n",
    "    active=len(depths) - 1,\n",
    "    currentvalue={\"prefix\": \"Depth: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=-0.99\n",
    "    )\n",
    ")\n",
    "\n",
    "config = {'responsive': False}\n",
    "\n",
    "# go.FigureWidget(data=fig)\n",
    "\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73718c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this app with `python app.py` and\n",
    "# visit http://127.0.0.1:8050/ in your web browser.\n",
    "\n",
    "\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, html, dcc\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "# assume you have a \"long-form\" data frame\n",
    "# see https://plotly.com/python/px-arguments/ for more options\n",
    "df = pd.DataFrame({\n",
    "    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n",
    "    \"Amount\": [4, 1, 2, 2, 4, 5],\n",
    "    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n",
    "})\n",
    "\n",
    "fig = px.bar(df, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for your data.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure=fig\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode=\"jupyterlab\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_grid_coords([(0, 0, 0), (0, 0, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = C\n",
    "t.descendant_pred()\n",
    "t.attr_label()\n",
    "\n",
    "nodes = list(t.nodes.values())\n",
    "sum_pred = sum(n.pred for n in nodes if n.pred is not None)\n",
    "N = len(t)\n",
    "indx_P_nodes, P_nodes = [], []\n",
    "for i, node in enumerate(nodes):\n",
    "    if (node.pred is not None and node.pred != 0):\n",
    "        if node.pred > sum_pred / 100: # only significant stuff\n",
    "            indx_P_nodes.append(i)\n",
    "            P_nodes.append(node)\n",
    "P_N = len(P_nodes)\n",
    "\n",
    "depths = t.get_depths()\n",
    "\n",
    "\n",
    "total_P = sum(n.pred for n in P_nodes)\n",
    "\n",
    "def comp_coords(assignment):\n",
    "    x_last = 0\n",
    "    x_partition = [x_last]\n",
    "    for assigned in assignment:\n",
    "        pred = P_nodes[assigned].pred\n",
    "        x_last += pred / total_P\n",
    "        x_partition.append(x_last)\n",
    "    assert abs(x_partition[-1] - 1) < 1e-6\n",
    "    return x_partition\n",
    "\n",
    "assignment = np.arange(P_N)\n",
    "\n",
    "\n",
    "def cost(assignment):\n",
    "    inverse_assignment = {P_nodes[j]: i for i, j in enumerate(assignment)}\n",
    "    cost = 0.\n",
    "    for node in nodes:\n",
    "        to_draw = np.zeros(P_N+1, dtype=bool)\n",
    "        for pred in node.preds:\n",
    "            if pred in P_nodes:\n",
    "                block = inverse_assignment[pred]\n",
    "                to_draw[block] = True\n",
    "        last_draw_here = None\n",
    "        time_since_last_draw = 0\n",
    "        for draw_here in to_draw:\n",
    "            if draw_here:\n",
    "                if last_draw_here is not None:\n",
    "                    cost += 1 + time_since_last_draw\n",
    "                last_draw_here = draw_here\n",
    "                time_since_last_draw = 0\n",
    "            time_since_last_draw += 1\n",
    "    return cost\n",
    "\n",
    "best = cost(assignment)\n",
    "best_assignment = assignment.copy()\n",
    "for _ in range(5000):\n",
    "    np.random.shuffle(assignment)\n",
    "    new_cost = cost(assignment)\n",
    "    if new_cost < best:\n",
    "        best = new_cost\n",
    "        best_assignment = assignment.copy()\n",
    "\n",
    "assignment = best_assignment\n",
    "print(best)\n",
    "\n",
    "inverse_assignment = {P_nodes[j]: i for i, j in enumerate(assignment)}\n",
    "x_partition = comp_coords(assignment)\n",
    "    \n",
    "fig = go.Figure()\n",
    "\n",
    "# Update axes properties\n",
    "fig.update_xaxes(\n",
    "    showticklabels=False,\n",
    "    showgrid=False,\n",
    "    zeroline=False,\n",
    "    range=[0, 1],\n",
    "    fixedrange=True\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    showticklabels=False,\n",
    "    showgrid=False,\n",
    "    zeroline=False,\n",
    "#     scaleanchor = \"x\",\n",
    "#     scaleratio = 1,\n",
    "#     range=[y_min - radius, y_max + radius]\n",
    ")\n",
    "\n",
    "def add_row(node, y=None, y_bottom=None, opacity=1., text=True):\n",
    "    to_draw = np.zeros(P_N+1, dtype=bool)\n",
    "    if y_bottom is None:\n",
    "        y_bottom = y - (1/len(nodes))\n",
    "    for pred in node.preds:\n",
    "        if pred in P_nodes:\n",
    "            block = inverse_assignment[pred]\n",
    "            to_draw[block] = True\n",
    "    x_coords, y_coords = [], []\n",
    "    prev = False\n",
    "    for i, draw_here in enumerate(to_draw):\n",
    "        if prev == False and draw_here == True:\n",
    "            if len(x_coords) > 0:\n",
    "                x_coords.append(None)\n",
    "                y_coords.append(None)\n",
    "            x_coords.append(x_partition[i])\n",
    "            x_coords.append(x_partition[i])\n",
    "            y_coords.append(y)\n",
    "            y_coords.append(y_bottom)\n",
    "        elif prev == True and draw_here == False:\n",
    "            x_coords.append(x_partition[i])\n",
    "            x_coords.append(x_partition[i])\n",
    "            y_coords.append(y_bottom)\n",
    "            y_coords.append(y)\n",
    "\n",
    "            x_coords.append(x_coords[len(x_coords) - 4])\n",
    "            y_coords.append(y_coords[len(y_coords) - 4])\n",
    "        prev = draw_here\n",
    "    if text == False:\n",
    "        text = ''\n",
    "    else:\n",
    "        text = [node.label] + ['' for _ in range(len(x_coords) - 1)]\n",
    "    fig.add_trace(go.Scatter(x=x_coords, y=y_coords, fill=\"toself\", opacity=opacity, mode=\"text\", fillcolor=node_to_color[node], textposition=\"bottom right\", text=text, visible=True)) # mode=\"lines\"\n",
    "\n",
    "y = - (len(nodes) - P_N) / len(nodes)\n",
    "for V_d in depths:\n",
    "    for node in V_d:\n",
    "        if not (node.pred is None or node.pred == 0.):\n",
    "            add_row(node, y=0, y_bottom=min(y*1.2, y-1/len(nodes)), opacity=0.1, text=False)\n",
    "            add_row(node, y=y, y_bottom=min(y*1.2, y-1/len(nodes)))\n",
    "\n",
    "y = 0\n",
    "for V_d in depths:\n",
    "    for node in V_d:\n",
    "        if node.pred is None or node.pred == 0.:\n",
    "            add_row(node, y=y)\n",
    "            y -= 1 / len(nodes)\n",
    "            \n",
    "config = dict({'scrollZoom': True})\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = C\n",
    "t.descendant_pred()\n",
    "t.add_parent_store()\n",
    "t.aggregate_pred(aggregate='sum')\n",
    "t.attr_label()\n",
    "\n",
    "nodes = list(t.nodes.values())\n",
    "sum_pred = sum(n.pred for n in nodes if n.pred is not None)\n",
    "N = len(t)\n",
    "indx_P_nodes, P_nodes = [], []\n",
    "for i, node in enumerate(nodes):\n",
    "    if (node.pred is not None and node.pred != 0):\n",
    "        if node.pred > sum_pred / 100: # only significant stuff\n",
    "            indx_P_nodes.append(i)\n",
    "            P_nodes.append(node)\n",
    "P_N = len(P_nodes)\n",
    "\n",
    "depths = t.get_depths()\n",
    "\n",
    "colors = plotly.colors.sample_colorscale(colorscale='Turbo', samplepoints=P_N)\n",
    "P_node_to_color = {P_node: colors[i] for i, P_node in enumerate(P_nodes)}\n",
    "\n",
    "node_to_color = {}\n",
    "for node in nodes:\n",
    "    desc_preds = node.preds\n",
    "    sum_preds = sum(desc.pred for desc in desc_preds)\n",
    "    rgb = 0.\n",
    "    for desc in desc_preds:\n",
    "        desc_color = np.array([x for x in map(int, re.findall(r'\\d+', P_node_to_color[desc]))])\n",
    "        rgb += (1/len(desc_preds)) * np.square(desc_color)\n",
    "    node_to_color[node] = 'rgb(' + ','.join([str(x) for x in np.sqrt(rgb)]) + ')'\n",
    "#     max_pred = -1\n",
    "#     desc = -1\n",
    "#     for desc_pred in desc_preds:\n",
    "#         if desc_pred.pred > max_pred:\n",
    "#             max_pred = desc_pred.pred\n",
    "#             desc = desc_pred\n",
    "#     node_to_color[node] = P_node_to_color[desc]\n",
    "\n",
    "source, target, value, color = [], [], [], []\n",
    "\n",
    "node_to_index = {node: i for i, node in enumerate(nodes)}\n",
    "for i, n in enumerate(nodes):\n",
    "    for c in n.children:\n",
    "        source.append(i)\n",
    "        target.append(node_to_index[c])\n",
    "        width = c.pred_agg\n",
    "        width /= len(c.parents)\n",
    "        value.append(width)\n",
    "        color.append(node_to_color[n])\n",
    "\n",
    "        \n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [n.label for n in nodes],\n",
    "      color = [node_to_color[n] for n in nodes]\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = source, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = target,\n",
    "      value = value,\n",
    "      color = color,\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Basic Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "np.array([x for x in map(int, re.findall(r'\\d+', colors[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8646d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.array([[0,0],[0,1],[1,1]])\n",
    "N_points = len(embedding)\n",
    "# move points away from eachother\n",
    "pw = pairwise_distances(embedding)\n",
    "for i in range(N_points):\n",
    "    pw[i,i] = np.inf\n",
    "indx = (pw == 0).nonzero()\n",
    "for i, j in zip(*indx):\n",
    "    pw[i,j] = np.inf\n",
    "F = np.divide(0.1, pw * pw)\n",
    "assert F.shape == pw.shape \n",
    "move = np.tile(embedding.reshape(N_points, 1, 2), (1, N_points, 1)) - np.tile(embedding.reshape(1, N_points, 2), (N_points, 1, 1))\n",
    "displacement = np.tile(F.reshape(N_points, N_points, 1), (1, 1, 2)) * move\n",
    "new = embedding + np.sum(displacement, axis=1)\n",
    "print(embedding)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(new).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc692f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[[44, 130]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2dede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=embedding[:, 0], y = embedding[:, 1])\n",
    "for i, lab in enumerate([n.label for n in P_nodes]):\n",
    "    plt.annotate(lab, (embedding[i, 0], embedding[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff31ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdac7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf311ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "min_x = -max_norm_embedding\n",
    "min_y = -max_norm_embedding\n",
    "max_x = max_norm_embedding\n",
    "max_y = max_norm_embedding\n",
    "box = Polygon([[min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]])\n",
    "\n",
    "# colorize\n",
    "for region in regions:\n",
    "#     polygon = vertices[region]\n",
    "    # Clipping polygon\n",
    "#     poly = Polygon(polygon)\n",
    "    poly = region.intersection(box)\n",
    "    polygon = [p for p in poly.exterior.coords]\n",
    "\n",
    "    plt.fill(*zip(*polygon), alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ee09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_x = -max_norm_embedding\n",
    "min_y = -max_norm_embedding\n",
    "max_x = max_norm_embedding\n",
    "max_y = max_norm_embedding\n",
    "box = Polygon([[min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]])\n",
    "\n",
    "# VORONOI COMPUTE\n",
    "points = MultiPoint(embedding.tolist())\n",
    "\n",
    "regions = voronoi_diagram(points, envelope=box)\n",
    "\n",
    "# colorize\n",
    "for region in regions:\n",
    "#     polygon = vertices[region]\n",
    "    # Clipping polygon\n",
    "#     poly = Polygon(polygon)\n",
    "    poly = region.intersection(box)\n",
    "    polygon = [p for p in poly.exterior.coords]\n",
    "    plt.fill(*zip(*polygon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colorize\n",
    "for region in regions:\n",
    "#     polygon = vertices[region]\n",
    "    # Clipping polygon\n",
    "#     poly = Polygon(polygon)\n",
    "    poly = region.intersection(box)\n",
    "    polygon = [p for p in poly.exterior.coords]\n",
    "    plt.fill(*zip(*polygon), alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_edge = np.zeros(embedding.shape)\n",
    "magnitude = np.linalg.norm(embedding, ord=5, axis=1)\n",
    "F_edge[:, 0] = (-embedding[:, 0]) * magnitude\n",
    "F_edge[:, 1] = (-embedding[:, 1]) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.linalg.norm(F_edge, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafce9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([p.pred for p in P])\n",
    "cross = weights.reshape(-1, 1)@weights.reshape(1, -1)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = weights.reshape(-1, 1)@weights.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94316fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross[5,4] == weights[5] * weights[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.arange(1000).reshape(10, 10, 10)\n",
    "x = (1, 2)\n",
    "test[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(2*n*m)[np.sum(cost_matrix_s, axis=3).reshape(-1) == 0]:\n",
    "    coord = (x//(n*m), (x//m)%n, x%m)\n",
    "    print(np.sum(cost_matrix_s, axis=3)[coord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix_s_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(np.argmin(cost_matrix_s_sum, axis=None), cost_matrix_s_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(options == np.min(options, axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (dict(a=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4feedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x['a']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30548a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
